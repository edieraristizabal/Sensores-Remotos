{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the pre-processed data to try out in this excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Ground Truth\n",
    "!mkdir Dataset\n",
    "!wget  https://zenodo.org/records/12751419/files/XdataV2.npy?download=1  -O Dataset/Xdata.npy\n",
    "!wget  https://zenodo.org/records/12751419/files/YdataV2.npy?download=1  -O Dataset/Ydata.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries to run machine learning model efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "\n",
    "keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code imports and preprocesses image data by loading numpy arrays and transposing them to match the required format for neural network frameworks. It begins by loading the image dataset (`Xdata.npy`) and the ground truth dataset (`Ydata.npy`) using `np.load()`, which reads the data from numpy array files stored in the \"Dataset\" directory. The `.transpose(0, 2, 3, 1)` method is applied to both datasets to rearrange their axes from (samples, channels, height, width) to (samples, height, width, channels), which is a common format for image data in deep learning. Finally, the shapes of the transposed datasets are printed to the console to confirm their dimensions. This includes the number of samples, the height and width of the images, and the number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and divide dataset\n",
    "Xdata = np.load(\"Dataset/Xdata.npy\").transpose(0, 2, 3, 1)\n",
    "Ydata = np.load(\"Dataset/Ydata.npy\").transpose(0, 2, 3, 1)\n",
    "print(f\"the shape of input image matrix is {Xdata.shape}\")\n",
    "print(f\"the shape of input GT matrix is {Ydata.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code visualizes a specific sample from the image dataset and its corresponding ground truth. It begins by setting the sample number `n` to 1354. Then, it creates a figure with two subplots side by side using `plt.subplots(1, 2, figsize=(12, 6))`. The left subplot (`ax[0]`) displays the second channel (index 1) of the image sample `Xdata` at index `n` using `ax[0].imshow(Xdata[n, :, :, 1])`. The right subplot (`ax[1]`) displays the first channel (index 0) of the corresponding ground truth sample `Ydata` at the same index using `ax[1].imshow(Ydata[n, :, :, 0])`. Finally, the tick labels on both subplots are formatted to use plain style without offset using `ax[0].ticklabel_format(useOffset=False, style=\"plain\")` and `ax[1].ticklabel_format(useOffset=False, style=\"plain\")`, which improves readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1354  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(Xdata[n, :, :, 1])\n",
    "ax[1].imshow(Ydata[n, :, :, 0])\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code splits the preprocessed image data into training and testing sets. The `train_test_split` function from the `sklearn.model_selection` module is used to divide `Xdata` (input images) and `Ydata` (ground truth labels) into `X_train` and `X_test` for the images, and `y_train` and `y_test` for the labels. The `test_size=0.3` parameter specifies that 30% of the data will be allocated to the test set, while the remaining 70% will be used for training. The `random_state=42` parameter ensures that the split is reproducible by setting a seed for the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xdata, Ydata, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Size of XTrain is {X_train.shape}\")\n",
    "print(f\" Size of XTest is {X_test.shape}\")\n",
    "print(f\" Size of YTrain is {y_train.shape}\")\n",
    "print(f\" Size of YTest is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet defines a U-Net model for image segmentation using the `segmentation_models` library. It begins with a commented line that shows an alternative way to create a U-Net model using the `sm.Unet` function, specifying a `resnet18` backbone, a single output class, and a sigmoid activation function. The actual code then constructs the U-Net model by calling the `Unet` function directly with the following parameters:\n",
    "\n",
    "- `backbone_name=\"resnet18\"`: Specifies the encoder backbone architecture, which is ResNet-18 in this case. ResNet-18 is a commonly used architecture known for its strong feature extraction capabilities.\n",
    "- `classes=1`: Indicates that the model has one output class, suitable for binary segmentation tasks.\n",
    "- `activation=\"sigmoid\"`: Uses the sigmoid activation function in the final layer, appropriate for binary classification problems where each pixel needs to be classified independently.\n",
    "- `encoder_weights=None`: Indicates that the encoder will not use pre-trained weights, which allows training the model from scratch.\n",
    "- `input_shape=(128, 128, 13)`: Defines the shape of the input images, which are 128x128 pixels with 13 channels.\n",
    "\n",
    "This setup creates a U-Net model tailored for image segmentation tasks with the specified input dimensions and architecture. For more details, you can refer to the [segmentation_models documentation](https://segmentation-models.readthedocs.io/en/latest/tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = sm.Unet('resnet18', classes=1, activation='sigmoid')\n",
    "# https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "model = Unet(\n",
    "    backbone_name=\"resnet18\",\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\",\n",
    "    encoder_weights=None,\n",
    "    input_shape=(128, 128, 13),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is configured for training with the Adam optimizer set at a learning rate of 1e-4 and the loss function specified as `binary_crossentropy`, which is suitable for binary classification tasks. Additionally, the model tracks accuracy and the area under the curve (AUC) as metrics. A training function is defined to train the model for 10 epochs, using a batch size of 32. It employs a checkpoint callback to save the best model based on validation loss at each epoch. The training process includes validation with 20% of the data, and class weights are adjusted to handle class imbalance, where class 1 is given more weight relative to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def trainmodel(model, xdata, ydata):\n",
    "    NUMBER_EPOCHS = 10\n",
    "    filepath = \"checkpointMaping\"\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    print(type(xdata), type(ydata))\n",
    "    hist = model.fit(\n",
    "        x=xdata,\n",
    "        y=ydata,\n",
    "        epochs=NUMBER_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,  # auto validate using 20% of random samples at each epoch\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        class_weight={0: 1, 1: 5},\n",
    "    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trainmodel` function is called to train the model using the training data. The input images `X_train` are converted to a NumPy array with the `dtype` set to `float32`, ensuring the data type is suitable for model training. The target labels `y_train` are also converted to a NumPy array with `dtype` set to `float32` and then expanded along the last axis to match the expected input shape of the model. This expansion is necessary because the model expects the labels to have a specific shape for binary classification. The function handles training the model with these inputs, applying the configured parameters and callbacks defined previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmodel(\n",
    "    model,\n",
    "    np.array(X_train, dtype=np.float32),\n",
    "    np.expand_dims(np.array(y_train, dtype=np.float32), axis=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code generates predictions for all images in the validation set by using the `model.predict` method on `X_test`. This method runs the trained model on the test data (`X_test`) to produce output predictions. The result, `val_preds`, contains the predicted probabilities or labels for each image in the test set, depending on the model's configuration. This step is essential for evaluating the model's performance on unseen data and for generating metrics such as accuracy or AUC on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all images in the validation set\n",
    "\n",
    "val_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment processes the model's predictions and calculates the accuracy score of the classification results. \n",
    "1. **Binary Thresholding:**\n",
    "   - `preds = val_preds` assigns the model’s predictions (`val_preds`) to the variable `preds`.\n",
    "   - `preds[preds > 0.50] = 1` sets the predicted values greater than 0.50 to 1. This converts probabilities to binary class labels based on a threshold of 0.50.\n",
    "   - `preds[preds <= 0.50] = 0` sets the predicted values less than or equal to 0.50 to 0, completing the binary classification.\n",
    "\n",
    "2. **Flattening and Accuracy Calculation:**\n",
    "   - `sklearn.metrics.accuracy_score(y_test.flatten(), preds.flatten())` calculates the accuracy score of the predictions. Both `y_test` and `preds` are flattened to ensure they are one-dimensional arrays, which is required by the `accuracy_score` function from `sklearn.metrics`. This function compares the flattened ground truth labels and predictions to compute the proportion of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.accuracy_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment processes the model's predictions and calculates the F1 score to evaluate classification performance.\n",
    "\n",
    "1. **Binary Thresholding:**\n",
    "   - `preds = val_preds` assigns the model’s predictions (`val_preds`) to the variable `preds`.\n",
    "   - `preds[preds > 0.50] = 1` sets prediction values greater than 0.50 to 1, converting probabilities into binary class labels based on a threshold of 0.50.\n",
    "   - `preds[preds <= 0.50] = 0` sets prediction values less than or equal to 0.50 to 0, completing the conversion into binary labels.\n",
    "\n",
    "2. **F1 Score Calculation:**\n",
    "   - `sklearn.metrics.f1_score(y_test.flatten(), preds.flatten())` computes the F1 score by comparing the flattened ground truth labels (`y_test`) with the flattened predictions (`preds`). The F1 score is the harmonic mean of precision and recall, providing a balanced measure of a model's accuracy, especially useful when dealing with imbalanced datasets. Flattening the arrays ensures that they are in the correct one-dimensional format for the `f1_score` function from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.f1_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code visualizes a sample from the validation predictions and the corresponding ground truth using matplotlib.\n",
    "\n",
    "1. **Sample Selection:**\n",
    "   - `n = 235` specifies the index of the sample to visualize.\n",
    "\n",
    "2. **Subplots Creation:**\n",
    "   - `fig, ax = plt.subplots(1, 2, figsize=(12, 6))` creates a figure with two side-by-side subplots, each with a size of 12 by 6 inches.\n",
    "\n",
    "3. **Image Display:**\n",
    "   - `ax[0].imshow(val_preds[n, :, :, :3].transpose((0, 1, 2)), vmin=0, vmax=0.5, cmap=\"plasma\")` displays the predicted output for the sample `n` in the first subplot (`ax[0]`). It uses the `plasma` colormap and sets the color scale to range from 0 to 0.5. The `.transpose((0, 1, 2))` reorders the image dimensions to (height, width, channels) for proper display.\n",
    "   - `ax[1].imshow(y_test[n, :, :, 0], cmap=\"plasma\")` shows the ground truth for the same sample in the second subplot (`ax[1]`), using the `plasma` colormap.\n",
    "\n",
    "4. **Tick Label Formatting:**\n",
    "   - `ax[0].ticklabel_format(useOffset=False, style=\"plain\")` and `ax[1].ticklabel_format(useOffset=False, style=\"plain\")` ensure that tick labels are displayed in plain format without scientific notation offsets.\n",
    "\n",
    "5. **Colorbars:**\n",
    "   - `fig.colorbar(im1, ax=ax[0])` adds a colorbar to the first subplot to indicate the color scale for the predicted values.\n",
    "   - `fig.colorbar(im2, ax=ax[1])` adds a colorbar to the second subplot to indicate the color scale for the ground truth.\n",
    "\n",
    "This visualization allows for direct comparison of the model's predictions against the actual ground truth for a specific sample, aiding in the evaluation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 235  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "im1 = ax[0].imshow(\n",
    "    val_preds[n, :, :, :3].transpose((0, 1, 2)), vmin=0, vmax=0.5, cmap=\"plasma\"\n",
    ")\n",
    "im2 = ax[1].imshow(y_test[n, :, :, 0], cmap=\"plasma\")\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "\n",
    "fig.colorbar(im1, ax=ax[0])\n",
    "fig.colorbar(im2, ax=ax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
